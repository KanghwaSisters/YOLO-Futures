{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1feec824",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c862f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from config import CONFIG\n",
    "from easydict import EasyDict\n",
    "\n",
    "from env.env import *\n",
    "from state.state import *\n",
    "from agent.PPOAgent_ms import *\n",
    "from models.CTTS import *\n",
    "from trainer.nonEpisodic import *\n",
    "from utils.setDevice import *\n",
    "from utils.timestepRelated import *\n",
    "from visualization.methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97e2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9c68b",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abbd783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>prevClose</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-16 09:01:00</th>\n",
       "      <td>20100216</td>\n",
       "      <td>901</td>\n",
       "      <td>207.55</td>\n",
       "      <td>207.65</td>\n",
       "      <td>207.50</td>\n",
       "      <td>207.60</td>\n",
       "      <td>207.5</td>\n",
       "      <td>3985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-16 09:02:00</th>\n",
       "      <td>20100216</td>\n",
       "      <td>902</td>\n",
       "      <td>207.60</td>\n",
       "      <td>207.65</td>\n",
       "      <td>207.25</td>\n",
       "      <td>207.55</td>\n",
       "      <td>207.5</td>\n",
       "      <td>5095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-16 09:03:00</th>\n",
       "      <td>20100216</td>\n",
       "      <td>903</td>\n",
       "      <td>207.55</td>\n",
       "      <td>207.80</td>\n",
       "      <td>207.50</td>\n",
       "      <td>207.60</td>\n",
       "      <td>207.5</td>\n",
       "      <td>2175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-16 09:04:00</th>\n",
       "      <td>20100216</td>\n",
       "      <td>904</td>\n",
       "      <td>207.55</td>\n",
       "      <td>207.85</td>\n",
       "      <td>207.55</td>\n",
       "      <td>207.80</td>\n",
       "      <td>207.5</td>\n",
       "      <td>1301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-16 09:05:00</th>\n",
       "      <td>20100216</td>\n",
       "      <td>905</td>\n",
       "      <td>207.80</td>\n",
       "      <td>208.15</td>\n",
       "      <td>207.80</td>\n",
       "      <td>208.05</td>\n",
       "      <td>207.5</td>\n",
       "      <td>3870.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date time    open    high     low   close  prevClose  \\\n",
       "2010-02-16 09:01:00  20100216  901  207.55  207.65  207.50  207.60      207.5   \n",
       "2010-02-16 09:02:00  20100216  902  207.60  207.65  207.25  207.55      207.5   \n",
       "2010-02-16 09:03:00  20100216  903  207.55  207.80  207.50  207.60      207.5   \n",
       "2010-02-16 09:04:00  20100216  904  207.55  207.85  207.55  207.80      207.5   \n",
       "2010-02-16 09:05:00  20100216  905  207.80  208.15  207.80  208.05      207.5   \n",
       "\n",
       "                        vol  \n",
       "2010-02-16 09:01:00  3985.0  \n",
       "2010-02-16 09:02:00  5095.0  \n",
       "2010-02-16 09:03:00  2175.0  \n",
       "2010-02-16 09:04:00  1301.0  \n",
       "2010-02-16 09:05:00  3870.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/processed/kospi200_ffill_clean_version.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc1f34",
   "metadata": {},
   "source": [
    "## Set State info • scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73505a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values = ['open', 'high', 'low', 'close', \n",
    "                'vol','return_5', 'return_10', 'volume_change', 'ema_5', \n",
    "                'ema_20', 'ema_cross', 'cci', 'sar', '%K', \n",
    "                # '%D', 'roc', 'rsi', 'obv', 'ad_line', \n",
    "                'bb_upper', 'bb_lower', 'bb_width', 'atr', 'gap_size']\n",
    "\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd500cb0",
   "metadata": {},
   "source": [
    "## Set Env info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fafab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2010-02-16', '2010-04-23'), ('2010-04-26', '2010-05-03')),\n",
       " (('2010-05-04', '2010-07-13'), ('2010-07-14', '2010-07-22')),\n",
       " (('2010-07-23', '2010-10-01'), ('2010-10-04', '2010-10-11')),\n",
       " (('2010-10-12', '2010-12-16'), ('2010-12-17', '2010-12-24')),\n",
       " (('2010-12-27', '2011-03-15'), ('2011-03-16', '2011-03-23'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_timestep = split_date_ranges_by_group(df.index[:100000])\n",
    "train_valid_timestep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6df86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "execution_strength = CONFIG.MAX_CONTRACT \n",
    "action_space = list(range(-execution_strength, execution_strength+1))\n",
    "n_actions = len(action_space)\n",
    "device = get_device() # torch.device(\"cpu\")  \n",
    "\n",
    "CONFIG.INPUT_DIM = len(target_values)\n",
    "CONFIG.REWARD_FTN = reward_unrealized_pnl_diff_log\n",
    "CONFIG.DONE_FTN = is_day_changed\n",
    "CONFIG.TRAIN_VALID_TIMESTEP = train_valid_timestep\n",
    "CONFIG.SCALER = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a45823",
   "metadata": {},
   "outputs": [],
   "source": [
    "state =  State(target_values)\n",
    "\n",
    "model = MultiStatePV(\n",
    "    input_dim=CONFIG.INPUT_DIM,\n",
    "    agent_input_dim=CONFIG.AGENT_INPUT_DIM,\n",
    "    embed_dim=CONFIG.EMBED_DIM,\n",
    "    kernel_size=CONFIG.KERNEL_SIZE,\n",
    "    stride=CONFIG.STRIDE,\n",
    "    action_size=CONFIG.N_ACTIONS,\n",
    "    device=device,\n",
    "    agent_hidden_dim=CONFIG.AGENT_HIDDEN_DIM,\n",
    "    agent_out_dim=CONFIG.AGENT_OUT_DIM,\n",
    "    fusion_hidden_dim=CONFIG.FUSION_HIDDEN_DIM,\n",
    "    num_layers=CONFIG.NUM_LAYERS,\n",
    "    num_heads=CONFIG.NUM_HEADS,\n",
    "    d_ff=CONFIG.D_FF,\n",
    "    dropout=CONFIG.DROPOUT\n",
    ")\n",
    "\n",
    "agent = PPOAgent(\n",
    "    action_space=CONFIG.ACTION_SPACE,\n",
    "    n_actions=CONFIG.N_ACTIONS,\n",
    "    model=model,\n",
    "    value_coeff=CONFIG.VALUE_COEFF,\n",
    "    entropy_coeff=CONFIG.ENTROPY_COEFF,\n",
    "    clip_eps=CONFIG.CLIP_EPS,\n",
    "    gamma=CONFIG.GAMMA,\n",
    "    lr=CONFIG.LR,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    epoch=CONFIG.EPOCH,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== [0] interval training ===========================\n",
      "Robust Scaling Completed.\n",
      "Robust Scaling Completed.\n",
      ">>>> Train : ('2010-02-16', '2010-04-23')\n",
      "[0|Train] Episode 0 | Loss:  0.2964 | (short : 38 %, hold : 12%, long: 50%) | (Ave) Strength: 239.00 |Reward: -18 | Avg(50): -18.30 | Maintained Len: 100\n",
      "[0|Train] Episode 1 | Loss:  0.2777 | (short : 44 %, hold : 8%, long: 48%) | (Ave) Strength: 227.00 |Reward: -19 | Avg(50): -18.41 | Maintained Len: 200\n",
      "[0|Train] Episode 2 | Loss:  0.2657 | (short : 53 %, hold : 9%, long: 38%) | (Ave) Strength: 223.33 |Reward: -17 | Avg(50): -17.98 | Maintained Len: 300\n",
      "[0|Train] Episode 3 | Loss:  1.2098 | (short : 45 %, hold : 13%, long: 42%) | (Ave) Strength: 224.00 |Reward: -45 | Avg(50): -24.73 | Maintained Len: 400\n",
      "[0|Train] Episode 4 | Loss:  0.4277 | (short : 40 %, hold : 17%, long: 43%) | (Ave) Strength: 218.60 |Reward: -26 | Avg(50): -25.06 | Maintained Len: 500\n",
      "[0|Train] Episode 5 | Loss:  1.1428 | (short : 42 %, hold : 13%, long: 45%) | (Ave) Strength: 217.00 |Reward: -36 | Avg(50): -26.90 | Maintained Len: 600\n",
      "[0|Train] Episode 6 | Loss:  0.1550 | (short : 44 %, hold : 11%, long: 45%) | (Ave) Strength: 214.71 |Reward: -13 | Avg(50): -24.96 | Maintained Len: 700\n",
      "[0|Train] Episode 7 | Loss:  0.0560 | (short : 47 %, hold : 16%, long: 37%) | (Ave) Strength: 212.50 |Reward:  -4 | Avg(50): -22.33 | Maintained Len: 800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m NonEpisodicTrainer(\n\u001b[1;32m      2\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m      3\u001b[0m     env\u001b[38;5;241m=\u001b[39mFuturesEnvironment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     path\u001b[38;5;241m=\u001b[39mCONFIG\u001b[38;5;241m.\u001b[39mPATH\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/trainer/nonEpisodic.py:68\u001b[0m, in \u001b[0;36mNonEpisodicTrainer.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_env, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_env(train_interval, valid_interval)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> Train : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>>> Valid : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m models \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest model\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_model, \n\u001b[1;32m     73\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighest reward\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_king_model, \n\u001b[1;32m     74\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper steps\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_per_steps[\u001b[38;5;241m0\u001b[39m]}\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/trainer/nonEpisodic.py:200\u001b[0m, in \u001b[0;36mNonEpisodicTrainer.train\u001b[0;34m(self, env, agent)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    198\u001b[0m mask \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mmask\n\u001b[0;32m--> 200\u001b[0m action, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m next_state, reward, done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m    202\u001b[0m current_position, execution_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_position_strength(action)\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/agent/PPOAgent_ms.py:89\u001b[0m, in \u001b[0;36mPPOAgent.get_action\u001b[0;34m(self, state, mask)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03mget_action(state: torch.Tensor) -> tuple[int, float]\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m- 샘플링된 행동의 로그 확률도 함께 반환한다.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     88\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(s\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m state)\n\u001b[0;32m---> 89\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# mask: shape [n_actions] with 1 (valid) or 0 (invalid)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(mask, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/models/CTTS.py:308\u001b[0m, in \u001b[0;36mMultiStatePV.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    307\u001b[0m     ts_state, agent_state \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 308\u001b[0m     ts_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeseries_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_state\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# (B, embed_dim)\u001b[39;00m\n\u001b[1;32m    309\u001b[0m     agent_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_block(agent_state)      \u001b[38;5;66;03m# (B, agent_out_dim)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     fused \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([ts_out, agent_out], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, embed + agent_out)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/models/CTTS.py:241\u001b[0m, in \u001b[0;36mCTTS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# x: (B, T=30, D)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(x)              \u001b[38;5;66;03m# (B, N_tokens, embed_dim)\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# (B, N_tokens, embed_dim)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# 대표 토큰을 사용 (e.g., 평균)\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)            \u001b[38;5;66;03m# (B, embed_dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/models/CTTS.py:186\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_emb(x)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 186\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/models/CTTS.py:146\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[0;34m(self, enc)\u001b[0m\n\u001b[1;32m    144\u001b[0m _x \u001b[38;5;241m=\u001b[39m enc\n\u001b[1;32m    145\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(_x)\n\u001b[0;32m--> 146\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# add and norm\u001b[39;00m\n\u001b[1;32m    149\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/YOLO-Futures/code/models/CTTS.py:94\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     91\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m reshape(q), reshape(k), reshape(v)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# calculate attention value\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m attention_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# concat heads --> result :  [batch_size, seq_len, d_model]\u001b[39;00m\n\u001b[1;32m     97\u001b[0m concated_value \u001b[38;5;241m=\u001b[39m attention_value\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(batch_size, seq_len, d_model)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = NonEpisodicTrainer(\n",
    "    df=df,\n",
    "    env=FuturesEnvironment,\n",
    "    train_valid_timestep=CONFIG.TRAIN_VALID_TIMESTEP,\n",
    "    window_size=CONFIG.WINDOW_SIZE,\n",
    "    state=state,\n",
    "    reward_ftn=CONFIG.REWARD_FTN,\n",
    "    done_ftn=CONFIG.DONE_FTN,\n",
    "    start_budget=CONFIG.START_BUDGET,\n",
    "    scaler=CONFIG.SCALER,\n",
    "    position_cap=CONFIG.POSITION_CAP,\n",
    "    agent=agent,\n",
    "    model=model,\n",
    "    optimizer=optim.Adam,\n",
    "    device=CONFIG.DEVICE,\n",
    "    n_steps=CONFIG.N_STEPS,\n",
    "    ma_interval=CONFIG.MA_INTERVAL,\n",
    "    save_interval=CONFIG.SAVE_INTERVAL,\n",
    "    path=CONFIG.PATH\n",
    ")\n",
    "\n",
    "trainer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
